# 第6章：卷积神经网络(CNN)

## 📝 本章目标
- 理解卷积操作原理
- 掌握CNN网络结构
- 学习经典CNN模型
- 实现图像分类项目

## 6.1 卷积层原理

```python
import numpy as np

def conv2d(image, kernel):
    """2D卷积操作"""
    h, w = image.shape
    kh, kw = kernel.shape
    
    output_h = h - kh + 1
    output_w = w - kw + 1
    output = np.zeros((output_h, output_w))
    
    for i in range(output_h):
        for j in range(output_w):
            region = image[i:i+kh, j:j+kw]
            output[i, j] = np.sum(region * kernel)
    
    return output

# 示例
image = np.random.rand(5, 5)
kernel = np.array([[1, 0, -1],
                   [1, 0, -1],
                   [1, 0, -1]])

result = conv2d(image, kernel)
```

## 6.2 池化层

```python
def max_pooling(image, pool_size=2):
    """最大池化"""
    h, w = image.shape
    new_h = h // pool_size
    new_w = w // pool_size
    
    output = np.zeros((new_h, new_w))
    
    for i in range(new_h):
        for j in range(new_w):
            region = image[i*pool_size:(i+1)*pool_size,
                          j*pool_size:(j+1)*pool_size]
            output[i, j] = np.max(region)
    
    return output
```

## 6.3 CNN模型实现

```python
from tensorflow import keras
from tensorflow.keras import layers

# 简单CNN模型
model = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

## 6.4 实战：猫狗分类

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 数据增强
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# 构建模型
model = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(512, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(
    optimizer=keras.optimizers.Adam(lr=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 训练
history = model.fit(
    train_generator,
    steps_per_epoch=100,
    epochs=30,
    validation_data=validation_generator,
    validation_steps=50
)
```

## 6.5 经典CNN架构

### LeNet-5
```python
def LeNet5():
    model = keras.Sequential([
        layers.Conv2D(6, 5, activation='tanh', input_shape=(28, 28, 1)),
        layers.AveragePooling2D(2),
        layers.Conv2D(16, 5, activation='tanh'),
        layers.AveragePooling2D(2),
        layers.Flatten(),
        layers.Dense(120, activation='tanh'),
        layers.Dense(84, activation='tanh'),
        layers.Dense(10, activation='softmax')
    ])
    return model
```

### VGG-16
```python
from tensorflow.keras.applications import VGG16

base_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

model = keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])
```

### ResNet
```python
from tensorflow.keras.applications import ResNet50

model = ResNet50(
    weights='imagenet',
    include_top=True,
    classes=1000
)
```

## 📚 本章小结
- ✅ 卷积和池化操作
- ✅ CNN网络结构
- ✅ 经典模型(LeNet, VGG, ResNet)
- ✅ 猫狗分类实战
- ✅ 迁移学习应用

[⬅️ 上一章](./05-深度学习基础.md) | [返回目录](../README.md) | [下一章 ➡️](./07-循环神经网络.md)
