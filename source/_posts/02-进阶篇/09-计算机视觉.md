# ç¬¬9ç« ï¼šè®¡ç®—æœºè§†è§‰è¿›é˜¶

## ğŸ“ æœ¬ç« ç›®æ ‡
- æŒæ¡ç›®æ ‡æ£€æµ‹ç®—æ³•
- å­¦ä¹ å›¾åƒåˆ†å‰²æŠ€æœ¯
- äº†è§£äººè„¸è¯†åˆ«ç³»ç»Ÿ
- å®ç°å®æ—¶ç‰©ä½“æ£€æµ‹

## 9.1 ç›®æ ‡æ£€æµ‹

### YOLOå®ç°

```python
from ultralytics import YOLO
import cv2

class ObjectDetector:
    def __init__(self, model_path='yolov8n.pt'):
        self.model = YOLO(model_path)
    
    def detect(self, image_path):
        results = self.model(image_path)
        return results[0].boxes
    
    def detect_realtime(self, video_source=0):
        cap = cv2.VideoCapture(video_source)
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            results = self.model(frame)
            annotated_frame = results[0].plot()
            
            cv2.imshow('Detection', annotated_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()

detector = ObjectDetector()
detector.detect_realtime()
```

## 9.2 å›¾åƒåˆ†å‰²

```python
from transformers import SegformerForSemanticSegmentation
import torch

class ImageSegmentation:
    def __init__(self):
        self.model = SegformerForSemanticSegmentation.from_pretrained(
            "nvidia/segformer-b0-finetuned-ade-512-512"
        )
    
    def segment(self, image):
        inputs = self.processor(images=image, return_tensors="pt")
        outputs = self.model(**inputs)
        logits = outputs.logits
        
        # åå¤„ç†
        upsampled_logits = nn.functional.interpolate(
            logits,
            size=image.size[::-1],
            mode="bilinear",
            align_corners=False
        )
        
        pred_seg = upsampled_logits.argmax(dim=1)[0]
        return pred_seg
```

## 9.3 äººè„¸è¯†åˆ«

```python
import face_recognition

class FaceRecognitionSystem:
    def __init__(self):
        self.known_faces = {}
    
    def register_face(self, name, image_path):
        image = face_recognition.load_image_file(image_path)
        encoding = face_recognition.face_encodings(image)[0]
        self.known_faces[name] = encoding
    
    def recognize(self, image_path):
        image = face_recognition.load_image_file(image_path)
        unknown_encoding = face_recognition.face_encodings(image)[0]
        
        results = []
        for name, known_encoding in self.known_faces.items():
            match = face_recognition.compare_faces([known_encoding], unknown_encoding)
            if match[0]:
                results.append(name)
        
        return results
```

## ğŸ“š æœ¬ç« å°ç»“
- âœ… YOLOç›®æ ‡æ£€æµ‹
- âœ… å›¾åƒåˆ†å‰²æŠ€æœ¯
- âœ… äººè„¸è¯†åˆ«ç³»ç»Ÿ
- âœ… å®æ—¶æ£€æµ‹åº”ç”¨

[â¬…ï¸ ä¸Šä¸€ç« ](./08-Transformeræ¶æ„.md) | [è¿”å›ç›®å½•](../README.md) | [ä¸‹ä¸€ç«  â¡ï¸](./10-è‡ªç„¶è¯­è¨€å¤„ç†.md)
