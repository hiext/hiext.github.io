# ç¬¬22ç« ï¼šAIåŒ»ç–—è¯Šæ–­åŠ©æ‰‹

## ğŸ“ é¡¹ç›®æ¦‚è¿°

å¼€å‘ä¸€ä¸ªæ™ºèƒ½åŒ»ç–—è¯Šæ–­è¾…åŠ©ç³»ç»Ÿï¼Œæ•´åˆå›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’ŒçŸ¥è¯†å›¾è°±æŠ€æœ¯ï¼Œä¸ºåŒ»ç”Ÿæä¾›è¯Šæ–­å»ºè®®ã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ğŸ”¬ åŒ»å­¦å½±åƒåˆ†æï¼ˆXå…‰ã€CTã€MRIï¼‰
- ğŸ“‹ ç—…å†æ–‡æœ¬ç†è§£ä¸ä¿¡æ¯æŠ½å–
- ğŸ§  åŸºäºçŸ¥è¯†å›¾è°±çš„è¯Šæ–­æ¨ç†
- ğŸ’Š ç”¨è¯å»ºè®®ä¸é£é™©é¢„è­¦
- ğŸ“Š å¯è§†åŒ–è¯Šæ–­æŠ¥å‘Šç”Ÿæˆ

**æŠ€æœ¯æ ˆ**ï¼š
- æ·±åº¦å­¦ä¹ ï¼šPyTorchã€TensorFlow
- å›¾åƒå¤„ç†ï¼šOpenCVã€Pillow
- NLPï¼šTransformersã€spaCy
- çŸ¥è¯†å›¾è°±ï¼šNeo4j
- Webæ¡†æ¶ï¼šFastAPIã€React

---

## 22.1 ç³»ç»Ÿæ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Webå‰ç«¯ç•Œé¢                      â”‚
â”‚         (React + Ant Design)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              åç«¯æœåŠ¡å±‚ (FastAPI)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åŒ»å­¦å½±åƒæ¨¡å—  â”‚  æ–‡æœ¬åˆ†ææ¨¡å—  â”‚  æ¨ç†å¼•æ“æ¨¡å— â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚            â”‚            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å½±åƒè¯†åˆ«æ¨¡å‹  â”‚  â”‚ NLPæ¨¡å‹  â”‚  â”‚ çŸ¥è¯†å›¾è°±     â”‚
â”‚ (ResNet/YOLO)â”‚  â”‚ (BERT)   â”‚  â”‚ (Neo4j)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 22.2 åŒ»å­¦å½±åƒåˆ†ææ¨¡å—

### 22.2.1 è‚ºéƒ¨Xå…‰ç‰‡åˆ†æ

```python
# è‚ºéƒ¨ç–¾ç—…æ£€æµ‹ç³»ç»Ÿ
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import cv2

class ChestXrayClassifier:
    """èƒ¸éƒ¨Xå…‰ç‰‡ç–¾ç—…åˆ†ç±»å™¨"""
    
    def __init__(self, model_path=None, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.model = self._build_model()
        
        if model_path:
            self.load_model(model_path)
        
        self.classes = [
            'æ­£å¸¸', 'è‚ºç‚', 'è‚ºç»“æ ¸', 'è‚ºç™Œ', 
            'æ°”èƒ¸', 'èƒ¸è…”ç§¯æ¶²', 'å¿ƒè„è‚¥å¤§'
        ]
        
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def _build_model(self):
        """æ„å»ºæ¨¡å‹"""
        # ä½¿ç”¨é¢„è®­ç»ƒçš„DenseNet
        model = models.densenet121(pretrained=True)
        
        # ä¿®æ”¹æœ€åä¸€å±‚
        num_features = model.classifier.in_features
        model.classifier = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 7)  # 7ç§ç–¾ç—…åˆ†ç±»
        )
        
        return model.to(self.device)
    
    def predict(self, image_path, grad_cam=True):
        """
        é¢„æµ‹Xå…‰ç‰‡
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            grad_cam: æ˜¯å¦ç”Ÿæˆçƒ­åŠ›å›¾
            
        Returns:
            é¢„æµ‹ç»“æœå’Œå¯è§†åŒ–
        """
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # é¢„æµ‹
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(image_tensor)
            probabilities = torch.softmax(outputs, dim=1)[0]
        
        # è·å–é¢„æµ‹ç»“æœ
        predictions = []
        for idx, prob in enumerate(probabilities):
            predictions.append({
                'disease': self.classes[idx],
                'probability': float(prob),
                'confidence': 'high' if prob > 0.7 else 'medium' if prob > 0.4 else 'low'
            })
        
        predictions.sort(key=lambda x: x['probability'], reverse=True)
        
        # ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾
        heatmap = None
        if grad_cam:
            heatmap = self._generate_gradcam(image_path, image_tensor)
        
        return {
            'predictions': predictions,
            'heatmap': heatmap,
            'primary_diagnosis': predictions[0]['disease'],
            'confidence': predictions[0]['confidence']
        }
    
    def _generate_gradcam(self, original_image_path, image_tensor):
        """ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾"""
        # ç®€åŒ–ç‰ˆGrad-CAMå®ç°
        self.model.eval()
        
        # å‰å‘ä¼ æ’­
        features = []
        gradients = []
        
        def forward_hook(module, input, output):
            features.append(output)
        
        def backward_hook(module, grad_input, grad_output):
            gradients.append(grad_output[0])
        
        # æ³¨å†Œhook
        target_layer = self.model.features[-1]
        forward_handle = target_layer.register_forward_hook(forward_hook)
        backward_handle = target_layer.register_backward_hook(backward_hook)
        
        # å‰å‘ä¼ æ’­
        output = self.model(image_tensor)
        
        # åå‘ä¼ æ’­
        self.model.zero_grad()
        target = output.argmax()
        output[0, target].backward()
        
        # è®¡ç®—æƒé‡
        pooled_gradients = torch.mean(gradients[0], dim=[0, 2, 3])
        
        # åŠ æƒç‰¹å¾å›¾
        for i in range(features[0].shape[1]):
            features[0][:, i, :, :] *= pooled_gradients[i]
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        heatmap = torch.mean(features[0], dim=1).squeeze()
        heatmap = np.maximum(heatmap.cpu().detach().numpy(), 0)
        heatmap = heatmap / heatmap.max()
        
        # ç§»é™¤hook
        forward_handle.remove()
        backward_handle.remove()
        
        # å åŠ åˆ°åŸå›¾
        original_image = cv2.imread(original_image_path)
        original_image = cv2.resize(original_image, (224, 224))
        
        heatmap_resized = cv2.resize(heatmap, (224, 224))
        heatmap_colored = cv2.applyColorMap(
            np.uint8(255 * heatmap_resized), 
            cv2.COLORMAP_JET
        )
        
        superimposed = cv2.addWeighted(
            original_image, 0.6, 
            heatmap_colored, 0.4, 
            0
        )
        
        return superimposed
    
    def batch_predict(self, image_paths):
        """æ‰¹é‡é¢„æµ‹"""
        results = []
        for path in image_paths:
            result = self.predict(path, grad_cam=False)
            results.append(result)
        return results
    
    def save_model(self, path):
        """ä¿å­˜æ¨¡å‹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'classes': self.classes
        }, path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {path}")
    
    def load_model(self, path):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.classes = checkpoint['classes']
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {path}")


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

# åˆå§‹åŒ–åˆ†ç±»å™¨
classifier = ChestXrayClassifier(device='cpu')

# é¢„æµ‹å•å¼ Xå…‰ç‰‡
result = classifier.predict('chest_xray.jpg')

print("ğŸ”¬ è¯Šæ–­ç»“æœ:")
print(f"ä¸»è¦è¯Šæ–­: {result['primary_diagnosis']}")
print(f"ç½®ä¿¡åº¦: {result['confidence']}")
print("\nè¯¦ç»†é¢„æµ‹:")
for pred in result['predictions'][:3]:
    print(f"  {pred['disease']}: {pred['probability']*100:.2f}%")
```

---

## 22.3 ç—…å†æ–‡æœ¬åˆ†ææ¨¡å—

### 22.3.1 å‘½åå®ä½“è¯†åˆ«

```python
# åŒ»ç–—æ–‡æœ¬NERç³»ç»Ÿ
from transformers import (
    AutoTokenizer, 
    AutoModelForTokenClassification,
    pipeline
)
import re

class MedicalNER:
    """åŒ»ç–—å‘½åå®ä½“è¯†åˆ«"""
    
    def __init__(self, model_name='bert-base-chinese'):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForTokenClassification.from_pretrained(
            model_name,
            num_labels=9  # å®ä½“ç±»å‹æ•°é‡
        )
        
        self.entity_labels = [
            'O',           # éå®ä½“
            'B-DISEASE',   # ç–¾ç—…-å¼€å§‹
            'I-DISEASE',   # ç–¾ç—…-å†…éƒ¨
            'B-SYMPTOM',   # ç—‡çŠ¶-å¼€å§‹
            'I-SYMPTOM',   # ç—‡çŠ¶-å†…éƒ¨
            'B-DRUG',      # è¯ç‰©-å¼€å§‹
            'I-DRUG',      # è¯ç‰©-å†…éƒ¨
            'B-TEST',      # æ£€æŸ¥-å¼€å§‹
            'I-TEST'       # æ£€æŸ¥-å†…éƒ¨
        ]
        
        self.ner_pipeline = pipeline(
            'ner',
            model=self.model,
            tokenizer=self.tokenizer
        )
    
    def extract_entities(self, text):
        """
        æå–åŒ»ç–—å®ä½“
        
        Args:
            text: ç—…å†æ–‡æœ¬
            
        Returns:
            æå–çš„å®ä½“å­—å…¸
        """
        # NERé¢„æµ‹
        ner_results = self.ner_pipeline(text)
        
        # æ•´åˆå®ä½“
        entities = {
            'diseases': [],
            'symptoms': [],
            'drugs': [],
            'tests': []
        }
        
        current_entity = None
        current_type = None
        
        for result in ner_results:
            label = result['entity']
            word = result['word']
            
            if label.startswith('B-'):
                # æ–°å®ä½“å¼€å§‹
                if current_entity:
                    self._add_entity(entities, current_type, current_entity)
                
                current_type = label[2:]
                current_entity = word
            
            elif label.startswith('I-') and current_entity:
                # å®ä½“ç»§ç»­
                current_entity += word
        
        # æ·»åŠ æœ€åä¸€ä¸ªå®ä½“
        if current_entity:
            self._add_entity(entities, current_type, current_entity)
        
        return entities
    
    def _add_entity(self, entities_dict, entity_type, entity_text):
        """æ·»åŠ å®ä½“åˆ°å­—å…¸"""
        type_map = {
            'DISEASE': 'diseases',
            'SYMPTOM': 'symptoms',
            'DRUG': 'drugs',
            'TEST': 'tests'
        }
        
        key = type_map.get(entity_type)
        if key and entity_text not in entities_dict[key]:
            entities_dict[key].append(entity_text)
    
    def analyze_medical_record(self, record_text):
        """
        åˆ†æå®Œæ•´ç—…å†
        
        Args:
            record_text: ç—…å†æ–‡æœ¬
            
        Returns:
            ç»“æ„åŒ–ç—…å†ä¿¡æ¯
        """
        # æå–å®ä½“
        entities = self.extract_entities(record_text)
        
        # æå–å…¶ä»–ä¿¡æ¯
        analysis = {
            'entities': entities,
            'patient_info': self._extract_patient_info(record_text),
            'chief_complaint': self._extract_chief_complaint(record_text),
            'history': self._extract_history(record_text)
        }
        
        return analysis
    
    def _extract_patient_info(self, text):
        """æå–æ‚£è€…ä¿¡æ¯"""
        info = {}
        
        # å¹´é¾„
        age_match = re.search(r'(\d+)å²', text)
        if age_match:
            info['age'] = int(age_match.group(1))
        
        # æ€§åˆ«
        if 'ç”·' in text[:50]:
            info['gender'] = 'ç”·'
        elif 'å¥³' in text[:50]:
            info['gender'] = 'å¥³'
        
        return info
    
    def _extract_chief_complaint(self, text):
        """æå–ä¸»è¯‰"""
        patterns = [
            r'ä¸»è¯‰[ï¼š:](.*?)(?:ç°ç—…å²|æ—¢å¾€å²|$)',
            r'ä¸»è¦ç—‡çŠ¶[ï¼š:](.*?)(?:\n|$)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1).strip()
        
        return ""
    
    def _extract_history(self, text):
        """æå–ç—…å²"""
        history = {}
        
        # ç°ç—…å²
        present_match = re.search(
            r'ç°ç—…å²[ï¼š:](.*?)(?:æ—¢å¾€å²|ä¸ªäººå²|$)', 
            text, 
            re.DOTALL
        )
        if present_match:
            history['present_illness'] = present_match.group(1).strip()
        
        # æ—¢å¾€å²
        past_match = re.search(
            r'æ—¢å¾€å²[ï¼š:](.*?)(?:ä¸ªäººå²|å®¶æ—å²|$)', 
            text, 
            re.DOTALL
        )
        if past_match:
            history['past_illness'] = past_match.group(1).strip()
        
        return history


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

# ç¤ºä¾‹ç—…å†
medical_record = """
æ‚£è€…å¼ ä¸‰ï¼Œç”·ï¼Œ45å²ã€‚
ä¸»è¯‰ï¼šåå¤å’³å—½ã€å’³ç—°ä¼´å‘çƒ­3å¤©ã€‚
ç°ç—…å²ï¼šæ‚£è€…3å¤©å‰æ— æ˜æ˜¾è¯±å› å‡ºç°å’³å—½ã€å’³ç—°ï¼Œç—°è‰²é»„ï¼Œä¼´å‘çƒ­ï¼Œ
ä½“æ¸©æœ€é«˜39.2â„ƒï¼Œä¼´ç•å¯’ã€ä¹åŠ›ã€‚
æ—¢å¾€å²ï¼šæœ‰é«˜è¡€å‹ç—…å²5å¹´ï¼Œè§„å¾‹æœç”¨ç¡è‹¯åœ°å¹³ç¼“é‡Šç‰‡ã€‚
ä½“æ ¼æ£€æŸ¥ï¼šä½“æ¸©38.5â„ƒï¼ŒåŒè‚ºå‘¼å¸éŸ³ç²—ï¼Œå¯é—»åŠæ¹¿å•°éŸ³ã€‚
è¾…åŠ©æ£€æŸ¥ï¼šè¡€å¸¸è§„ç¤ºç™½ç»†èƒ12.5Ã—10^9/Lï¼Œä¸­æ€§ç²’ç»†èƒ85%ã€‚
èƒ¸éƒ¨Xçº¿ç‰‡ç¤ºå³ä¸‹è‚ºç‚æ€§æ”¹å˜ã€‚
"""

# åˆ†æç—…å†
ner = MedicalNER()
analysis = ner.analyze_medical_record(medical_record)

print("ğŸ“‹ ç—…å†åˆ†æç»“æœ:")
print(f"\næ‚£è€…ä¿¡æ¯: {analysis['patient_info']}")
print(f"\nä¸»è¯‰: {analysis['chief_complaint']}")
print(f"\næå–çš„å®ä½“:")
for entity_type, entities in analysis['entities'].items():
    if entities:
        print(f"  {entity_type}: {', '.join(entities)}")
```

---

## 22.4 è¯Šæ–­æ¨ç†å¼•æ“

### 22.4.1 åŸºäºè§„åˆ™çš„æ¨ç†

```python
# è¯Šæ–­æ¨ç†ç³»ç»Ÿ
from typing import List, Dict
import json

class DiagnosisReasoner:
    """è¯Šæ–­æ¨ç†å¼•æ“"""
    
    def __init__(self, knowledge_base_path='medical_kb.json'):
        self.knowledge_base = self._load_knowledge_base(knowledge_base_path)
        self.diagnosis_history = []
    
    def _load_knowledge_base(self, path):
        """åŠ è½½åŒ»å­¦çŸ¥è¯†åº“"""
        # ç®€åŒ–çš„çŸ¥è¯†åº“ç»“æ„
        kb = {
            'è‚ºç‚': {
                'symptoms': ['å’³å—½', 'å’³ç—°', 'å‘çƒ­', 'èƒ¸ç—›'],
                'tests': ['è¡€å¸¸è§„å¼‚å¸¸', 'Xçº¿è‚ºéƒ¨é˜´å½±'],
                'risk_factors': ['å¸çƒŸ', 'å…ç–«åŠ›ä½ä¸‹'],
                'severity_indicators': ['é«˜çƒ­', 'å‘¼å¸å›°éš¾', 'æ„è¯†éšœç¢'],
                'treatment': ['æŠ—ç”Ÿç´ ', 'æ­¢å’³åŒ–ç—°', 'é€€çƒ­']
            },
            'è‚ºç»“æ ¸': {
                'symptoms': ['å’³å—½', 'å’³ç—°', 'ä½çƒ­', 'ç›—æ±—', 'æ¶ˆç˜¦'],
                'tests': ['ç—°æ¶‚ç‰‡é˜³æ€§', 'Xçº¿è‚ºéƒ¨ç©ºæ´'],
                'risk_factors': ['æ¥è§¦å²', 'å…ç–«åŠ›ä½ä¸‹'],
                'severity_indicators': ['å’¯è¡€', 'å‘¼å¸è¡°ç«­'],
                'treatment': ['æŠ—ç»“æ ¸è¯ç‰©', 'è¥å…»æ”¯æŒ']
            },
            'å¿ƒåŠ›è¡°ç«­': {
                'symptoms': ['å‘¼å¸å›°éš¾', 'æ°´è‚¿', 'ä¹åŠ›'],
                'tests': ['å¿ƒè„è¶…å£°å¼‚å¸¸', 'BNPå‡é«˜'],
                'risk_factors': ['é«˜è¡€å‹', 'å† å¿ƒç—…', 'å¿ƒè‚Œç—…'],
                'severity_indicators': ['ç«¯åå‘¼å¸', 'å°‘å°¿'],
                'treatment': ['åˆ©å°¿å‰‚', 'å¼ºå¿ƒè¯']
            }
        }
        
        return kb
    
    def reason(self, symptoms: List[str], test_results: List[str], 
               patient_history: Dict = None):
        """
        è¯Šæ–­æ¨ç†
        
        Args:
            symptoms: ç—‡çŠ¶åˆ—è¡¨
            test_results: æ£€æŸ¥ç»“æœåˆ—è¡¨
            patient_history: æ‚£è€…ç—…å²
            
        Returns:
            è¯Šæ–­å»ºè®®
        """
        diagnoses = []
        
        # éå†çŸ¥è¯†åº“ä¸­çš„ç–¾ç—…
        for disease, disease_info in self.knowledge_base.items():
            score = self._calculate_disease_score(
                disease_info,
                symptoms,
                test_results,
                patient_history
            )
            
            if score > 0:
                # è¯„ä¼°ä¸¥é‡ç¨‹åº¦
                severity = self._assess_severity(
                    disease_info,
                    symptoms,
                    test_results
                )
                
                diagnoses.append({
                    'disease': disease,
                    'confidence': min(score / 10, 1.0),
                    'severity': severity,
                    'matched_symptoms': self._get_matched_items(
                        symptoms, 
                        disease_info['symptoms']
                    ),
                    'matched_tests': self._get_matched_items(
                        test_results,
                        disease_info['tests']
                    ),
                    'treatment_suggestions': disease_info['treatment']
                })
        
        # æ’åº
        diagnoses.sort(key=lambda x: x['confidence'], reverse=True)
        
        # ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        report = self._generate_report(diagnoses, symptoms, test_results)
        
        return {
            'diagnoses': diagnoses,
            'report': report
        }
    
    def _calculate_disease_score(self, disease_info, symptoms, 
                                  test_results, patient_history):
        """è®¡ç®—ç–¾ç—…è¯„åˆ†"""
        score = 0
        
        # ç—‡çŠ¶åŒ¹é…
        for symptom in symptoms:
            if symptom in disease_info['symptoms']:
                score += 3
        
        # æ£€æŸ¥ç»“æœåŒ¹é…
        for test in test_results:
            if any(test in t for t in disease_info['tests']):
                score += 5
        
        # é£é™©å› ç´ 
        if patient_history:
            for risk in disease_info.get('risk_factors', []):
                if risk in str(patient_history):
                    score += 2
        
        return score
    
    def _assess_severity(self, disease_info, symptoms, test_results):
        """è¯„ä¼°ç–¾ç—…ä¸¥é‡ç¨‹åº¦"""
        severity_score = 0
        
        for indicator in disease_info.get('severity_indicators', []):
            if indicator in symptoms or indicator in str(test_results):
                severity_score += 1
        
        if severity_score >= 2:
            return 'severe'
        elif severity_score == 1:
            return 'moderate'
        else:
            return 'mild'
    
    def _get_matched_items(self, input_list, reference_list):
        """è·å–åŒ¹é…é¡¹"""
        matched = []
        for item in input_list:
            if item in reference_list:
                matched.append(item)
        return matched
    
    def _generate_report(self, diagnoses, symptoms, test_results):
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
        report = {
            'summary': '',
            'primary_diagnosis': None,
            'differential_diagnoses': [],
            'recommendations': []
        }
        
        if diagnoses:
            primary = diagnoses[0]
            report['primary_diagnosis'] = primary['disease']
            
            # æ‘˜è¦
            report['summary'] = f"""
åŸºäºæ‚£è€…ç—‡çŠ¶ï¼ˆ{', '.join(symptoms)}ï¼‰å’Œæ£€æŸ¥ç»“æœï¼ˆ{', '.join(test_results)}ï¼‰ï¼Œ
åˆæ­¥è¯Šæ–­ä¸º{primary['disease']}ï¼Œç½®ä¿¡åº¦{primary['confidence']*100:.1f}%ï¼Œ
ç–¾ç—…ä¸¥é‡ç¨‹åº¦è¯„ä¼°ä¸º{primary['severity']}ã€‚
            """.strip()
            
            # é‰´åˆ«è¯Šæ–­
            if len(diagnoses) > 1:
                report['differential_diagnoses'] = [
                    d['disease'] for d in diagnoses[1:3]
                ]
            
            # å»ºè®®
            report['recommendations'] = [
                f"å»ºè®®æ²»ç–—æ–¹æ¡ˆï¼š{', '.join(primary['treatment_suggestions'])}",
                "å»ºè®®è¿›ä¸€æ­¥å®Œå–„ç›¸å…³æ£€æŸ¥",
                "å¯†åˆ‡è§‚å¯Ÿç—…æƒ…å˜åŒ–"
            ]
            
            if primary['severity'] == 'severe':
                report['recommendations'].insert(0, "âš ï¸ ç—…æƒ…è¾ƒé‡ï¼Œå»ºè®®ç«‹å³ä½é™¢æ²»ç–—")
        
        return report


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

reasoner = DiagnosisReasoner()

# è¾“å…¥ç—‡çŠ¶å’Œæ£€æŸ¥ç»“æœ
symptoms = ['å’³å—½', 'å’³ç—°', 'å‘çƒ­', 'èƒ¸ç—›']
test_results = ['è¡€å¸¸è§„å¼‚å¸¸', 'Xçº¿è‚ºéƒ¨é˜´å½±']
history = {'past_illness': 'å¸çƒŸå²20å¹´'}

# æ¨ç†è¯Šæ–­
result = reasoner.reason(symptoms, test_results, history)

print("ğŸ§  è¯Šæ–­æ¨ç†ç»“æœ:")
print(f"\n{result['report']['summary']}")
print(f"\nä¸»è¦è¯Šæ–­: {result['report']['primary_diagnosis']}")

if result['report']['differential_diagnoses']:
    print(f"é‰´åˆ«è¯Šæ–­: {', '.join(result['report']['differential_diagnoses'])}")

print("\nğŸ’Š æ²»ç–—å»ºè®®:")
for rec in result['report']['recommendations']:
    print(f"  â€¢ {rec}")

print("\nè¯¦ç»†è¯Šæ–­åˆ—è¡¨:")
for diag in result['diagnoses']:
    print(f"\n  {diag['disease']} (ç½®ä¿¡åº¦: {diag['confidence']*100:.1f}%)")
    print(f"    åŒ¹é…ç—‡çŠ¶: {', '.join(diag['matched_symptoms'])}")
    print(f"    ä¸¥é‡ç¨‹åº¦: {diag['severity']}")
```

---

## 22.5 å®Œæ•´ç³»ç»Ÿé›†æˆ

```python
# å®Œæ•´çš„AIåŒ»ç–—è¯Šæ–­åŠ©æ‰‹
from datetime import datetime
import uuid

class MedicalDiagnosisAssistant:
    """AIåŒ»ç–—è¯Šæ–­åŠ©æ‰‹ - å®Œæ•´ç³»ç»Ÿ"""
    
    def __init__(self):
        self.xray_classifier = ChestXrayClassifier()
        self.ner = MedicalNER()
        self.reasoner = DiagnosisReasoner()
        
        self.session_id = str(uuid.uuid4())
        self.diagnosis_history = []
    
    def diagnose(self, patient_data):
        """
        å®Œæ•´è¯Šæ–­æµç¨‹
        
        Args:
            patient_data: {
                'medical_record': ç—…å†æ–‡æœ¬,
                'xray_image': Xå…‰ç‰‡è·¯å¾„(å¯é€‰),
                'patient_info': æ‚£è€…åŸºæœ¬ä¿¡æ¯
            }
        """
        diagnosis_result = {
            'session_id': self.session_id,
            'timestamp': datetime.now().isoformat(),
            'patient_info': patient_data.get('patient_info', {}),
            'image_analysis': None,
            'text_analysis': None,
            'final_diagnosis': None
        }
        
        # 1. å½±åƒåˆ†æ
        if 'xray_image' in patient_data:
            print("ğŸ”¬ æ­£åœ¨åˆ†æåŒ»å­¦å½±åƒ...")
            image_result = self.xray_classifier.predict(
                patient_data['xray_image']
            )
            diagnosis_result['image_analysis'] = image_result
        
        # 2. ç—…å†æ–‡æœ¬åˆ†æ
        if 'medical_record' in patient_data:
            print("ğŸ“‹ æ­£åœ¨åˆ†æç—…å†æ–‡æœ¬...")
            text_result = self.ner.analyze_medical_record(
                patient_data['medical_record']
            )
            diagnosis_result['text_analysis'] = text_result
        
        # 3. ç»¼åˆæ¨ç†
        print("ğŸ§  æ­£åœ¨è¿›è¡Œè¯Šæ–­æ¨ç†...")
        symptoms = []
        test_results = []
        
        # ä»æ–‡æœ¬åˆ†æè·å–ç—‡çŠ¶
        if diagnosis_result['text_analysis']:
            symptoms = diagnosis_result['text_analysis']['entities'].get('symptoms', [])
            test_results = diagnosis_result['text_analysis']['entities'].get('tests', [])
        
        # ä»å½±åƒåˆ†æè·å–è¯Šæ–­
        if diagnosis_result['image_analysis']:
            primary_image_diagnosis = diagnosis_result['image_analysis']['primary_diagnosis']
            if primary_image_diagnosis != 'æ­£å¸¸':
                test_results.append(f'Xå…‰æ˜¾ç¤º{primary_image_diagnosis}')
        
        # æ¨ç†
        reasoning_result = self.reasoner.reason(
            symptoms=symptoms,
            test_results=test_results,
            patient_history=diagnosis_result.get('text_analysis', {}).get('history')
        )
        
        diagnosis_result['final_diagnosis'] = reasoning_result
        
        # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        diagnosis_result['comprehensive_report'] = self._generate_comprehensive_report(
            diagnosis_result
        )
        
        # ä¿å­˜å†å²
        self.diagnosis_history.append(diagnosis_result)
        
        return diagnosis_result
    
    def _generate_comprehensive_report(self, diagnosis_result):
        """ç”Ÿæˆç»¼åˆè¯Šæ–­æŠ¥å‘Š"""
        report = {
            'title': 'åŒ»ç–—è¯Šæ–­è¾…åŠ©æŠ¥å‘Š',
            'timestamp': diagnosis_result['timestamp'],
            'sections': []
        }
        
        # æ‚£è€…ä¿¡æ¯
        if diagnosis_result.get('patient_info'):
            report['sections'].append({
                'title': 'æ‚£è€…ä¿¡æ¯',
                'content': diagnosis_result['patient_info']
            })
        
        # å½±åƒåˆ†æ
        if diagnosis_result.get('image_analysis'):
            ia = diagnosis_result['image_analysis']
            report['sections'].append({
                'title': 'å½±åƒå­¦åˆ†æ',
                'content': f"ä¸»è¦å‘ç°: {ia['primary_diagnosis']} (ç½®ä¿¡åº¦: {ia['confidence']})"
            })
        
        # ä¸´åºŠè¡¨ç°
        if diagnosis_result.get('text_analysis'):
            ta = diagnosis_result['text_analysis']
            report['sections'].append({
                'title': 'ä¸´åºŠè¡¨ç°',
                'content': {
                    'ä¸»è¯‰': ta.get('chief_complaint'),
                    'ç—‡çŠ¶': ta['entities'].get('symptoms', []),
                    'æ£€æŸ¥': ta['entities'].get('tests', [])
                }
            })
        
        # è¯Šæ–­ç»“è®º
        if diagnosis_result.get('final_diagnosis'):
            fd = diagnosis_result['final_diagnosis']
            report['sections'].append({
                'title': 'è¯Šæ–­ç»“è®º',
                'content': fd['report']
            })
        
        return report
    
    def print_report(self, diagnosis_result):
        """æ‰“å°è¯Šæ–­æŠ¥å‘Š"""
        report = diagnosis_result['comprehensive_report']
        
        print("\n" + "="*60)
        print(f"  {report['title']}")
        print("="*60)
        print(f"ç”Ÿæˆæ—¶é—´: {report['timestamp']}\n")
        
        for section in report['sections']:
            print(f"\nã€{section['title']}ã€‘")
            print("-" * 60)
            
            content = section['content']
            if isinstance(content, dict):
                for key, value in content.items():
                    print(f"{key}: {value}")
            else:
                print(content)
        
        print("\n" + "="*60)


# ========== å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ ==========

if __name__ == "__main__":
    # åˆå§‹åŒ–ç³»ç»Ÿ
    assistant = MedicalDiagnosisAssistant()
    
    # å‡†å¤‡æ‚£è€…æ•°æ®
    patient_data = {
        'patient_info': {
            'name': 'å¼ ä¸‰',
            'age': 45,
            'gender': 'ç”·'
        },
        'medical_record': medical_record,  # å‰é¢å®šä¹‰çš„ç—…å†
        # 'xray_image': 'chest_xray.jpg'  # å¯é€‰
    }
    
    # æ‰§è¡Œè¯Šæ–­
    print("ğŸ¥ AIåŒ»ç–—è¯Šæ–­åŠ©æ‰‹")
    print("="*60)
    
    result = assistant.diagnose(patient_data)
    
    # æ‰“å°æŠ¥å‘Š
    assistant.print_report(result)
    
    print("\nâœ… è¯Šæ–­å®Œæˆï¼")
    print("\nâš ï¸  æ³¨æ„ï¼šæœ¬ç³»ç»Ÿä»…ä¾›è¾…åŠ©å‚è€ƒï¼Œæœ€ç»ˆè¯Šæ–­éœ€ç”±ä¸“ä¸šåŒ»ç”Ÿç¡®è®¤ã€‚")
```

---

## ğŸ“š æœ¬ç« å°ç»“

- âœ… å¼€å‘äº†åŒ»å­¦å½±åƒåˆ†ææ¨¡å—ï¼ˆXå…‰ç‰‡åˆ†ç±»ï¼‰
- âœ… å®ç°äº†ç—…å†æ–‡æœ¬NERå’Œä¿¡æ¯æŠ½å–
- âœ… æ„å»ºäº†åŸºäºè§„åˆ™çš„è¯Šæ–­æ¨ç†å¼•æ“
- âœ… é›†æˆäº†å®Œæ•´çš„AIåŒ»ç–—è¯Šæ–­åŠ©æ‰‹ç³»ç»Ÿ
- âœ… ç”Ÿæˆäº†ç»“æ„åŒ–çš„è¯Šæ–­æŠ¥å‘Š

**é¡¹ç›®äº®ç‚¹**ï¼š
- å¤šæ¨¡æ€æ•°æ®èåˆï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰
- Grad-CAMå¯è§£é‡Šæ€§
- çŸ¥è¯†é©±åŠ¨çš„æ¨ç†
- å®Œæ•´çš„ä¸´åºŠåº”ç”¨æµç¨‹

---

## ğŸ¯ æ‰©å±•æ–¹å‘

1. **åŠŸèƒ½æ‰©å±•**ï¼š
   - æ”¯æŒæ›´å¤šåŒ»å­¦å½±åƒç±»å‹ï¼ˆCTã€MRIï¼‰
   - é›†æˆçŸ¥è¯†å›¾è°±è¿›è¡Œæ·±åº¦æ¨ç†
   - æ·»åŠ ç”¨è¯å»ºè®®å’Œç›¸äº’ä½œç”¨æ£€æŸ¥

2. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - æ¨¡å‹è’¸é¦æå‡æ¨ç†é€Ÿåº¦
   - è¾¹ç¼˜éƒ¨ç½²æ”¯æŒç¦»çº¿ä½¿ç”¨
   - è”é‚¦å­¦ä¹ ä¿æŠ¤éšç§

3. **å·¥ç¨‹åŒ–**ï¼š
   - Dockerå®¹å™¨åŒ–éƒ¨ç½²
   - RESTful APIæ¥å£
   - Webå‰ç«¯ç•Œé¢å¼€å‘
   - ä¸åŒ»é™¢HISç³»ç»Ÿå¯¹æ¥

---

[â¬…ï¸ ä¸Šä¸€ç« ](./21-è¯­éŸ³æŠ€æœ¯åº”ç”¨.md) | [è¿”å›ç›®å½•](../README.md) | [ä¸‹ä¸€ç«  â¡ï¸](./23-é‡‘èé£æ§ç³»ç»Ÿ.md)
