# 第4章：AI必备数学基础

## 📝 本章目标
- 掌握线性代数核心概念
- 理解概率论与统计基础
- 学习微积分在AI中的应用
- 掌握梯度下降优化算法

## 4.1 线性代数

### 4.1.1 向量和矩阵

```python
import numpy as np

# 向量运算
v1 = np.array([1, 2, 3])
v2 = np.array([4, 5, 6])

print("向量加法:", v1 + v2)
print("点积:", np.dot(v1, v2))
print("向量范数:", np.linalg.norm(v1))

# 矩阵运算
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

print("矩阵乘法:\n", np.matmul(A, B))
print("矩阵转置:\n", A.T)
print("矩阵的逆:\n", np.linalg.inv(A))
print("特征值:", np.linalg.eigvals(A))
```

### 4.1.2 线性变换

```python
# 旋转矩阵
theta = np.pi / 4  # 45度
rotation_matrix = np.array([
    [np.cos(theta), -np.sin(theta)],
    [np.sin(theta), np.cos(theta)]
])

# 应用变换
point = np.array([1, 0])
rotated = rotation_matrix @ point
print("旋转后的点:", rotated)
```

## 4.2 概率论与统计

### 4.2.1 概率分布

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# 正态分布
mu, sigma = 0, 1
x = np.linspace(-4, 4, 100)
y = stats.norm.pdf(x, mu, sigma)

plt.plot(x, y, label='正态分布 N(0,1)')
plt.xlabel('x')
plt.ylabel('概率密度')
plt.title('正态分布')
plt.legend()
plt.grid(True)
plt.show()

# 贝叶斯定理应用
# P(A|B) = P(B|A) * P(A) / P(B)
def bayes_theorem(p_b_given_a, p_a, p_b):
    return (p_b_given_a * p_a) / p_b

# 示例：医疗诊断
p_positive_given_disease = 0.99  # 有病测出阳性的概率
p_disease = 0.01  # 患病率
p_positive = 0.05  # 测出阳性的概率

p_disease_given_positive = bayes_theorem(
    p_positive_given_disease, p_disease, p_positive
)
print(f"测出阳性时真患病的概率: {p_disease_given_positive:.2%}")
```

### 4.2.2 期望与方差

```python
# 计算期望和方差
data = np.random.randn(1000)

mean = np.mean(data)
variance = np.var(data)
std = np.std(data)

print(f"期望(均值): {mean:.4f}")
print(f"方差: {variance:.4f}")
print(f"标准差: {std:.4f}")

# 协方差矩阵
X = np.random.randn(100, 3)
cov_matrix = np.cov(X.T)
print("协方差矩阵:\n", cov_matrix)
```

## 4.3 微积分

### 4.3.1 导数与梯度

```python
# 数值求导
def numerical_gradient(f, x, h=1e-4):
    grad = np.zeros_like(x)
    for i in range(x.size):
        tmp_val = x[i]
        x[i] = tmp_val + h
        fxh1 = f(x)
        
        x[i] = tmp_val - h
        fxh2 = f(x)
        
        grad[i] = (fxh1 - fxh2) / (2*h)
        x[i] = tmp_val
    return grad

# 示例函数 f(x,y) = x^2 + y^2
def f(x):
    return np.sum(x**2)

x = np.array([3.0, 4.0])
gradient = numerical_gradient(f, x)
print("梯度:", gradient)  # [6.0, 8.0]
```

### 4.3.2 梯度下降

```python
class GradientDescent:
    def __init__(self, lr=0.01):
        self.lr = lr
        self.history = []
    
    def optimize(self, f, init_x, num_steps=100):
        x = init_x.copy()
        
        for i in range(num_steps):
            grad = numerical_gradient(f, x)
            x -= self.lr * grad
            self.history.append((x.copy(), f(x)))
        
        return x
    
    def plot_history(self):
        values = [v for _, v in self.history]
        plt.plot(values)
        plt.xlabel('迭代次数')
        plt.ylabel('函数值')
        plt.title('优化过程')
        plt.grid(True)
        plt.show()

# 使用梯度下降
optimizer = GradientDescent(lr=0.1)
init_x = np.array([5.0, 5.0])
optimal_x = optimizer.optimize(f, init_x)
print("最优解:", optimal_x)
optimizer.plot_history()
```

## 4.4 实战：线性回归数学推导

```python
class LinearRegressionMath:
    """从数学角度理解线性回归"""
    
    def __init__(self):
        self.w = None
        self.b = None
    
    def fit_normal_equation(self, X, y):
        """正规方程法 - 解析解"""
        # 添加偏置列
        X_b = np.c_[np.ones((X.shape[0], 1)), X]
        
        # θ = (X^T X)^-1 X^T y
        theta = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y
        
        self.b = theta[0]
        self.w = theta[1:]
        
        return self
    
    def fit_gradient_descent(self, X, y, lr=0.01, epochs=1000):
        """梯度下降法"""
        m, n = X.shape
        self.w = np.zeros(n)
        self.b = 0
        
        for _ in range(epochs):
            # 预测
            y_pred = X @ self.w + self.b
            
            # 计算梯度
            dw = (1/m) * X.T @ (y_pred - y)
            db = (1/m) * np.sum(y_pred - y)
            
            # 更新参数
            self.w -= lr * dw
            self.b -= lr * db
        
        return self
    
    def predict(self, X):
        return X @ self.w + self.b

# 示例数据
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X.squeeze() + np.random.randn(100)

# 正规方程法
model1 = LinearRegressionMath()
model1.fit_normal_equation(X, y)
print("正规方程 - w:", model1.w, "b:", model1.b)

# 梯度下降法
model2 = LinearRegressionMath()
model2.fit_gradient_descent(X, y, lr=0.1, epochs=1000)
print("梯度下降 - w:", model2.w, "b:", model2.b)
```

## 4.5 信息论基础

### 4.5.1 熵与交叉熵

```python
def entropy(p):
    """计算熵"""
    return -np.sum(p * np.log2(p + 1e-10))

def cross_entropy(p, q):
    """交叉熵"""
    return -np.sum(p * np.log2(q + 1e-10))

def kl_divergence(p, q):
    """KL散度"""
    return np.sum(p * np.log2((p + 1e-10) / (q + 1e-10)))

# 示例
p = np.array([0.5, 0.3, 0.2])
q = np.array([0.4, 0.4, 0.2])

print(f"熵 H(P): {entropy(p):.4f}")
print(f"交叉熵 H(P,Q): {cross_entropy(p, q):.4f}")
print(f"KL散度 D(P||Q): {kl_divergence(p, q):.4f}")
```

## 4.6 优化算法对比

```python
class Optimizers:
    """各种优化算法实现"""
    
    @staticmethod
    def sgd(params, grads, lr=0.01):
        """随机梯度下降"""
        for param, grad in zip(params, grads):
            param -= lr * grad
    
    @staticmethod
    def momentum(params, grads, v, lr=0.01, momentum=0.9):
        """动量法"""
        for param, grad, vel in zip(params, grads, v):
            vel[:] = momentum * vel - lr * grad
            param += vel
    
    @staticmethod
    def adam(params, grads, m, v, t, lr=0.001, beta1=0.9, beta2=0.999):
        """Adam优化器"""
        eps = 1e-8
        t += 1
        
        for param, grad, mi, vi in zip(params, grads, m, v):
            mi[:] = beta1 * mi + (1 - beta1) * grad
            vi[:] = beta2 * vi + (1 - beta2) * (grad ** 2)
            
            m_hat = mi / (1 - beta1 ** t)
            v_hat = vi / (1 - beta2 ** t)
            
            param -= lr * m_hat / (np.sqrt(v_hat) + eps)
        
        return t
```

## 📚 本章小结
- ✅ 线性代数：向量、矩阵运算
- ✅ 概率统计：分布、贝叶斯定理
- ✅ 微积分：导数、梯度下降
- ✅ 信息论：熵、交叉熵、KL散度
- ✅ 优化算法：SGD、Momentum、Adam

## 🎯 练习题
1. 实现矩阵的特征值分解
2. 用贝叶斯定理解决实际问题
3. 比较不同优化算法的收敛速度
4. 推导逻辑回归的损失函数梯度

[⬅️ 上一章](./03-Python编程基础.md) | [返回目录](../README.md) | [下一章 ➡️](../02-进阶篇/05-深度学习基础.md)
