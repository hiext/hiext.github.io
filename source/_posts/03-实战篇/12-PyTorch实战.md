# ç¬¬12ç« ï¼šPyTorchå®æˆ˜

## ğŸ“ æœ¬ç« ç›®æ ‡
- æŒæ¡PyTorchæ ¸å¿ƒæ¦‚å¿µ
- å­¦ä¹ åŠ¨æ€è®¡ç®—å›¾
- å®ç°è‡ªå®šä¹‰æ¨¡å‹
- æŒæ¡è®­ç»ƒæŠ€å·§

## 12.1 PyTorchåŸºç¡€

```python
import torch
import torch.nn as nn

# å¼ é‡åˆ›å»º
x = torch.tensor([1, 2, 3])
y = torch.zeros(3, 3)
z = torch.randn(2, 2)

# è‡ªåŠ¨æ±‚å¯¼
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
y = x ** 2
y.sum().backward()
print(x.grad)  # dy/dx = 2x
```

## 12.2 ç¥ç»ç½‘ç»œæ¨¡å‹

```python
class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        x = x.view(-1, 784)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

model = SimpleNet()
```

## 12.3 è®­ç»ƒæµç¨‹

```python
import torch.optim as optim
from torch.utils.data import DataLoader

# æ•°æ®åŠ è½½
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# å®šä¹‰æ¨¡å‹ã€æŸå¤±ã€ä¼˜åŒ–å™¨
model = SimpleNet()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒå¾ªç¯
for epoch in range(10):
    model.train()
    total_loss = 0
    
    for images, labels in train_loader:
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}')
```

## 12.4 CNNå®ç°

```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)
        self.pool = nn.MaxPool2d(2)
        self.dropout = nn.Dropout(0.25)
    
    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 9216)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
```

## 12.5 è¿ç§»å­¦ä¹ 

```python
import torchvision.models as models

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
resnet = models.resnet18(pretrained=True)

# å†»ç»“å‚æ•°
for param in resnet.parameters():
    param.requires_grad = False

# æ›¿æ¢æœ€åä¸€å±‚
resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)

# åªè®­ç»ƒæœ€åä¸€å±‚
optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)
```

## 12.6 æ¨¡å‹ä¿å­˜

```python
# ä¿å­˜æ•´ä¸ªæ¨¡å‹
torch.save(model, 'model.pth')
model = torch.load('model.pth')

# åªä¿å­˜å‚æ•°
torch.save(model.state_dict(), 'model_weights.pth')
model.load_state_dict(torch.load('model_weights.pth'))

# ä¿å­˜è®­ç»ƒçŠ¶æ€
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss
}
torch.save(checkpoint, 'checkpoint.pth')
```

## ğŸ“š æœ¬ç« å°ç»“
- âœ… PyTorchå¼ é‡æ“ä½œ
- âœ… åŠ¨æ€è®¡ç®—å›¾
- âœ… è‡ªå®šä¹‰æ¨¡å‹æ„å»º
- âœ… å®Œæ•´è®­ç»ƒæµç¨‹
- âœ… è¿ç§»å­¦ä¹ å’Œæ¨¡å‹ä¿å­˜

[â¬…ï¸ ä¸Šä¸€ç« ](./11-TensorFlowå®æˆ˜.md) | [è¿”å›ç›®å½•](../README.md) | [ä¸‹ä¸€ç«  â¡ï¸](./13-å¤§è¯­è¨€æ¨¡å‹åº”ç”¨.md)
