# ç¬¬14ç« ï¼šAIæ¨¡å‹éƒ¨ç½²

## ğŸ“ æœ¬ç« ç›®æ ‡
- æŒæ¡æ¨¡å‹éƒ¨ç½²æµç¨‹
- å­¦ä¹ Flask/FastAPIéƒ¨ç½²
- äº†è§£Dockerå®¹å™¨åŒ–
- å®ç°äº‘å¹³å°éƒ¨ç½²

## 14.1 Flaskéƒ¨ç½²

```python
from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)
model = joblib.load('model.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    prediction = model.predict([data['features']])
    return jsonify({'prediction': prediction.tolist()})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## 14.2 FastAPIéƒ¨ç½²

```python
from fastapi import FastAPI
from pydantic import BaseModel
import torch

app = FastAPI()

class PredictionInput(BaseModel):
    features: list

@app.post("/predict")
async def predict(input_data: PredictionInput):
    # åŠ è½½æ¨¡å‹
    model = torch.load('model.pth')
    prediction = model(torch.tensor(input_data.features))
    return {"prediction": prediction.tolist()}
```

## 14.3 Dockeréƒ¨ç½²

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## 14.4 æ¨¡å‹ä¼˜åŒ–

```python
# TensorFlow Lite
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model('saved_model')
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

# ONNXå¯¼å‡º
import torch.onnx

dummy_input = torch.randn(1, 3, 224, 224)
torch.onnx.export(model, dummy_input, "model.onnx")
```

## ğŸ“š æœ¬ç« å°ç»“
- âœ… Flask/FastAPIéƒ¨ç½²
- âœ… Dockerå®¹å™¨åŒ–
- âœ… æ¨¡å‹ä¼˜åŒ–æŠ€æœ¯
- âœ… äº‘å¹³å°éƒ¨ç½²æ–¹æ¡ˆ

[â¬…ï¸ ä¸Šä¸€ç« ](./13-å¤§è¯­è¨€æ¨¡å‹åº”ç”¨.md) | [è¿”å›ç›®å½•](../README.md) | [ä¸‹ä¸€ç«  â¡ï¸](./15-MLOpså·¥ç¨‹åŒ–.md)
