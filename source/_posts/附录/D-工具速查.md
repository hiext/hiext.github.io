# é™„å½•Dï¼šå·¥å…·ä¸æ¡†æ¶é€ŸæŸ¥è¡¨

## ğŸ PythonåŸºç¡€

```python
# åˆ—è¡¨æ¨å¯¼å¼
[x**2 for x in range(10) if x % 2 == 0]

# Lambdaå‡½æ•°
sorted(data, key=lambda x: x['score'])

# è£…é¥°å™¨
@timer
def my_function():
    pass
```

## ğŸ”¢ NumPyé€ŸæŸ¥

```python
import numpy as np

# åˆ›å»º
np.array([1,2,3])
np.zeros((3,4))
np.arange(0, 10, 2)
np.linspace(0, 1, 5)

# è¿ç®—
a + b
np.dot(a, b)
np.matmul(A, B)

# ç»Ÿè®¡
np.mean(arr)
np.std(arr)
np.argmax(arr)
```

## ğŸ“Š Pandasé€ŸæŸ¥

```python
import pandas as pd

# åˆ›å»º
df = pd.DataFrame(data)
s = pd.Series([1,2,3])

# è¯»å†™
pd.read_csv('file.csv')
df.to_csv('file.csv')

# æ“ä½œ
df.head()
df.describe()
df[df['age'] > 25]
df.groupby('city').mean()
```

## ğŸ“ˆ Matplotlibé€ŸæŸ¥

```python
import matplotlib.pyplot as plt

# åŸºç¡€ç»˜å›¾
plt.plot(x, y)
plt.scatter(x, y)
plt.bar(categories, values)
plt.hist(data, bins=30)

# è®¾ç½®
plt.xlabel('Xè½´')
plt.title('æ ‡é¢˜')
plt.legend()
plt.grid(True)
```

## ğŸ§  TensorFlow/Kerasé€ŸæŸ¥

```python
from tensorflow import keras

# æ¨¡å‹æ„å»º
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# ç¼–è¯‘
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# è®­ç»ƒ
model.fit(X_train, y_train, epochs=10, batch_size=32)

# é¢„æµ‹
model.predict(X_test)
```

## ğŸ”¥ PyTorché€ŸæŸ¥

```python
import torch
import torch.nn as nn

# å¼ é‡
x = torch.tensor([1,2,3])
x.to('cuda')

# æ¨¡å‹
class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(10, 2)
    
    def forward(self, x):
        return self.fc(x)

# è®­ç»ƒ
optimizer = torch.optim.Adam(model.parameters())
loss_fn = nn.CrossEntropyLoss()

optimizer.zero_grad()
loss.backward()
optimizer.step()
```

## ğŸ¤— Transformersé€ŸæŸ¥

```python
from transformers import pipeline, AutoModel

# Pipeline
classifier = pipeline("sentiment-analysis")
result = classifier("I love this!")

# åŠ è½½æ¨¡å‹
model = AutoModel.from_pretrained("bert-base-chinese")
```

## ğŸ“š scikit-learné€ŸæŸ¥

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# åˆ†å‰²æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# è®­ç»ƒ
model = RandomForestClassifier()
model.fit(X_train, y_train)

# è¯„ä¼°
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)
```

## ğŸ”— LangChainé€ŸæŸ¥

```python
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# LLM
llm = OpenAI(temperature=0.7)

# Prompt
template = PromptTemplate(
    input_variables=["topic"],
    template="å†™ä¸€ç¯‡å…³äº{topic}çš„æ–‡ç« "
)

# Chain
chain = LLMChain(llm=llm, prompt=template)
result = chain.run("AI")
```

## ğŸ¨ Stable Diffusioné€ŸæŸ¥

```python
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
image = pipe("a cat in a garden").images[0]
```

## ğŸŒ FastAPIé€ŸæŸ¥

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class Item(BaseModel):
    name: str
    price: float

@app.get("/")
def read_root():
    return {"Hello": "World"}

@app.post("/items/")
def create_item(item: Item):
    return item

# è¿è¡Œ: uvicorn main:app --reload
```

## ğŸ³ Dockeré€ŸæŸ¥

```bash
# æ„å»ºé•œåƒ
docker build -t myapp .

# è¿è¡Œå®¹å™¨
docker run -p 8000:8000 myapp

# æŸ¥çœ‹å®¹å™¨
docker ps

# åœæ­¢å®¹å™¨
docker stop container_id
```

## ğŸ“ Gité€ŸæŸ¥

```bash
# åˆå§‹åŒ–
git init

# æäº¤
git add .
git commit -m "message"

# æ¨é€
git push origin main

# åˆ†æ”¯
git branch feature
git checkout feature
```

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

### pipåŒ…ç®¡ç†
```bash
pip install package
pip install -r requirements.txt
pip freeze > requirements.txt
pip list
pip show package
```

### condaç¯å¢ƒ
```bash
conda create -n env_name python=3.10
conda activate env_name
conda install package
conda list
conda env export > environment.yml
```

## âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. å‘é‡åŒ–æ“ä½œ
```python
# æ…¢
result = []
for x in data:
    result.append(x ** 2)

# å¿«
result = np.array(data) ** 2
```

### 2. ä½¿ç”¨GPU
```python
# TensorFlow
with tf.device('/GPU:0'):
    model.fit(X, y)

# PyTorch
model = model.to('cuda')
```

### 3. æ‰¹å¤„ç†
```python
# ä½¿ç”¨DataLoader
from torch.utils.data import DataLoader
loader = DataLoader(dataset, batch_size=32)
```

## ğŸ› è°ƒè¯•æŠ€å·§

```python
# æ–­ç‚¹è°ƒè¯•
import pdb; pdb.set_trace()

# æ‰“å°å½¢çŠ¶
print(f"Shape: {tensor.shape}")

# æ£€æŸ¥NaN
np.isnan(array).any()

# å†…å­˜ä½¿ç”¨
import psutil
print(f"Memory: {psutil.virtual_memory().percent}%")
```

[è¿”å›ç›®å½•](../README.md)
