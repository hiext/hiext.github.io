# ç¬¬20ç« ï¼šAIå†…å®¹ç”Ÿæˆåº”ç”¨

## ğŸ“ æœ¬ç« ç›®æ ‡
- æŒæ¡æ–‡æœ¬ç”ŸæˆæŠ€æœ¯
- å­¦ä¹ å›¾åƒç”Ÿæˆæ¨¡å‹
- äº†è§£è§†é¢‘ç”Ÿæˆæ–¹æ³•
- å¼€å‘å†…å®¹ç”Ÿæˆå¹³å°

## 20.1 æ–‡æœ¬ç”Ÿæˆ

```python
from transformers import GPT2LMHeadModel, GPT2Tokenizer

class TextGenerator:
    def __init__(self, model_name='gpt2-chinese'):
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)
        self.model = GPT2LMHeadModel.from_pretrained(model_name)
    
    def generate(self, prompt, max_length=100):
        inputs = self.tokenizer.encode(prompt, return_tensors='pt')
        outputs = self.model.generate(
            inputs,
            max_length=max_length,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            temperature=0.7
        )
        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return text

generator = TextGenerator()
article = generator.generate("äººå·¥æ™ºèƒ½çš„æœªæ¥æ˜¯")
```

## 20.2 å›¾åƒç”Ÿæˆ(Stable Diffusion)

```python
from diffusers import StableDiffusionPipeline
import torch

class ImageGenerator:
    def __init__(self):
        self.pipe = StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16
        )
        self.pipe = self.pipe.to("cuda")
    
    def generate(self, prompt, num_images=1):
        images = self.pipe(
            prompt,
            num_inference_steps=50,
            guidance_scale=7.5,
            num_images_per_prompt=num_images
        ).images
        return images

gen = ImageGenerator()
images = gen.generate("ä¸€åªå¯çˆ±çš„çŒ«å’ªåœ¨èŠ±å›­é‡Œç©è€")
```

## 20.3 è¥é”€æ–‡æ¡ˆç”Ÿæˆå™¨

```python
class MarketingCopyGenerator:
    def __init__(self):
        from langchain.llms import OpenAI
        from langchain.prompts import PromptTemplate
        
        self.llm = OpenAI(temperature=0.7)
        
        self.template = PromptTemplate(
            input_variables=["product", "features", "target_audience"],
            template="""
            ä½œä¸ºä¸“ä¸šçš„è¥é”€æ–‡æ¡ˆæ’°å†™è€…ï¼Œä¸ºä»¥ä¸‹äº§å“æ’°å†™å¸å¼•äººçš„è¥é”€æ–‡æ¡ˆï¼š
            
            äº§å“ï¼š{product}
            ç‰¹ç‚¹ï¼š{features}
            ç›®æ ‡å—ä¼—ï¼š{target_audience}
            
            è¯·ç”Ÿæˆï¼š
            1. äº§å“æ ‡é¢˜ï¼ˆå¸å¼•çœ¼çƒï¼‰
            2. äº§å“æè¿°ï¼ˆ200å­—å·¦å³ï¼‰
            3. ä¸‰ä¸ªå–ç‚¹ï¼ˆæ¯ä¸ª30å­—ä»¥å†…ï¼‰
            4. è¡ŒåŠ¨å·å¬è¯­
            """
        )
    
    def generate_copy(self, product, features, target_audience):
        prompt = self.template.format(
            product=product,
            features=features,
            target_audience=target_audience
        )
        return self.llm(prompt)

generator = MarketingCopyGenerator()
copy = generator.generate_copy(
    product="æ™ºèƒ½æ‰‹è¡¨",
    features="å¿ƒç‡ç›‘æµ‹ã€GPSå®šä½ã€50ç±³é˜²æ°´",
    target_audience="25-40å²è¿åŠ¨çˆ±å¥½è€…"
)
```

## 20.4 AIè§†é¢‘ç”Ÿæˆ

```python
class VideoGenerator:
    def __init__(self):
        from moviepy.editor import ImageClip, concatenate_videoclips
        self.ImageClip = ImageClip
        self.concatenate = concatenate_videoclips
    
    def create_video_from_images(self, image_paths, duration=3):
        clips = []
        for img_path in image_paths:
            clip = self.ImageClip(img_path).set_duration(duration)
            clips.append(clip)
        
        video = self.concatenate(clips)
        return video
    
    def add_audio(self, video, audio_path):
        from moviepy.editor import AudioFileClip
        audio = AudioFileClip(audio_path)
        video = video.set_audio(audio)
        return video
```

## ğŸ“š æœ¬ç« å°ç»“
- âœ… GPTæ–‡æœ¬ç”Ÿæˆ
- âœ… Stable Diffusionå›¾åƒç”Ÿæˆ
- âœ… è¥é”€æ–‡æ¡ˆè‡ªåŠ¨åŒ–
- âœ… è§†é¢‘å†…å®¹ç”Ÿæˆ

[â¬…ï¸ ä¸Šä¸€ç« ](./19-é¢„æµ‹åˆ†æç³»ç»Ÿ.md) | [è¿”å›ç›®å½•](../README.md) | [ä¸‹ä¸€ç«  â¡ï¸](./21-è¯­éŸ³æŠ€æœ¯åº”ç”¨.md)
