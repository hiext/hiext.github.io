# ç¬¬17ç« ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

## ğŸ“ æœ¬ç« ç›®æ ‡
- ç†è§£å¯¹è¯ç³»ç»Ÿæ¶æ„
- æŒæ¡æ„å›¾è¯†åˆ«æŠ€æœ¯
- å­¦ä¹ å¯¹è¯ç®¡ç†ç­–ç•¥
- å¼€å‘å®Œæ•´æ™ºèƒ½å®¢æœ

## 17.1 å¯¹è¯ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ·è¾“å…¥ â†’ æ„å›¾è¯†åˆ« â†’ æ§½ä½å¡«å…… â†’ å¯¹è¯ç®¡ç† â†’ å›å¤ç”Ÿæˆ â†’ ç”¨æˆ·è¾“å‡º
```

## 17.2 æ„å›¾è¯†åˆ«

```python
from transformers import pipeline

class IntentClassifier:
    def __init__(self):
        self.classifier = pipeline(
            "text-classification",
            model="bert-base-chinese"
        )
        
        self.intents = {
            'æŸ¥è¯¢è®¢å•': ['è®¢å•', 'ç‰©æµ', 'å¿«é€’'],
            'é€€æ¢è´§': ['é€€è´§', 'æ¢è´§', 'é€€æ¬¾'],
            'äº§å“å’¨è¯¢': ['ä»·æ ¼', 'åŠŸèƒ½', 'å‚æ•°'],
            'æŠ•è¯‰å»ºè®®': ['æŠ•è¯‰', 'å»ºè®®', 'å·®è¯„']
        }
    
    def predict(self, text):
        result = self.classifier(text)[0]
        return result['label'], result['score']
```

## 17.3 å¯¹è¯ç®¡ç†

```python
class DialogueManager:
    def __init__(self):
        self.context = {}
        self.state = 'idle'
    
    def process(self, user_input, intent):
        if intent == 'æŸ¥è¯¢è®¢å•':
            if 'order_id' not in self.context:
                return "è¯·æä¾›æ‚¨çš„è®¢å•å·"
            else:
                return self.query_order(self.context['order_id'])
        
        elif intent == 'é€€æ¢è´§':
            return self.handle_return()
        
        else:
            return "æˆ‘ä¸å¤ªç†è§£ï¼Œèƒ½å…·ä½“è¯´æ˜å—ï¼Ÿ"
    
    def query_order(self, order_id):
        # æŸ¥è¯¢è®¢å•é€»è¾‘
        return f"è®¢å•{order_id}çš„çŠ¶æ€æ˜¯ï¼šå·²å‘è´§"
    
    def handle_return(self):
        return "è¯·æä¾›è®¢å•å·å’Œé€€è´§åŸå› "
```

## 17.4 å®Œæ•´å®¢æœç³»ç»Ÿ

```python
class CustomerServiceBot:
    def __init__(self):
        self.intent_classifier = IntentClassifier()
        self.dialogue_manager = DialogueManager()
        self.history = []
    
    def chat(self, user_input):
        # æ„å›¾è¯†åˆ«
        intent, confidence = self.intent_classifier.predict(user_input)
        
        # å¯¹è¯ç®¡ç†
        response = self.dialogue_manager.process(user_input, intent)
        
        # è®°å½•å†å²
        self.history.append({
            'user': user_input,
            'bot': response,
            'intent': intent
        })
        
        return response

# ä½¿ç”¨
bot = CustomerServiceBot()
print(bot.chat("æˆ‘æƒ³æŸ¥è¯¢è®¢å•"))
print(bot.chat("è®¢å•å·æ˜¯12345"))
```

## 17.5 åŸºäºRAGçš„å®¢æœ

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI

class RAGCustomerService:
    def __init__(self, knowledge_base_path):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            persist_directory=knowledge_base_path,
            embedding_function=self.embeddings
        )
        self.llm = OpenAI(temperature=0.7)
    
    def answer(self, question):
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = self.vectorstore.similarity_search(question, k=3)
        
        # æ„å»ºæç¤ºè¯
        context = "\n".join([doc.page_content for doc in docs])
        prompt = f"""
        åŸºäºä»¥ä¸‹çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ï¼š
        
        çŸ¥è¯†ï¼š
        {context}
        
        é—®é¢˜ï¼š{question}
        
        å›ç­”ï¼š
        """
        
        # ç”Ÿæˆå›å¤
        response = self.llm(prompt)
        return response
```

## ğŸ“š æœ¬ç« å°ç»“
- âœ… å¯¹è¯ç³»ç»Ÿæ¶æ„
- âœ… æ„å›¾è¯†åˆ«å®ç°
- âœ… å¯¹è¯ç®¡ç†ç­–ç•¥
- âœ… å®Œæ•´å®¢æœç³»ç»Ÿ
- âœ… RAGå¢å¼ºå®¢æœ

[â¬…ï¸ ä¸Šä¸€ç« ](./16-æ¨èç³»ç»Ÿ.md) | [è¿”å›ç›®å½•](../README.md) | [ä¸‹ä¸€ç«  â¡ï¸](./18-å›¾åƒè¯†åˆ«åº”ç”¨.md)
